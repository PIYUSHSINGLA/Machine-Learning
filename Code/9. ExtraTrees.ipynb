{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___Extremely Randomized Trees - Supervised Machine Learning___\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___What are Extremely Randomized Trees?___\n",
    "\n",
    "_Extra Trees or Extremely Randomized Trees is like Random Forest which aggregates the results of multiple de-correlated decision trees collected in a “forest” to output it’s result, in that it builds multiple trees and splits nodes using random subsets of features, but with two key differences: it does not bootstrap observations (meaning it samples without replacement), and nodes are split on random splits, not best splits. So, in summary, ExtraTrees:_\n",
    "\n",
    "* _Builds multiple trees with bootstrap = False by default, which means it samples without replacement._\n",
    "* _Nodes are split based on random splits among a random subset of the features selected at every node._\n",
    "\n",
    "_In Extra Trees, randomness doesn’t come from bootstrapping of data, but rather comes from the random splits of all observations. Extra Trees can be used both for regression and classification. (Low Variance)_\n",
    "\n",
    "_The Extra Trees algorithm works by creating a large number of unpruned decision trees from the training dataset. Predictions are made by averaging the prediction of the decision trees in the case of regression or using majority voting in the case of classification._\n",
    "\n",
    "_As such, there are three main hyperparameters to tune in the algorithm; they are the number of decision trees in the ensemble, the number of input features to randomly select and consider for each split point, and the minimum number of samples required in a node to create a new split point._\n",
    "\n",
    "___When to choose Extratrees?___ _Extra trees seem to keep a higher performance than Random Forest in presence of noisy features._"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Difference between Random Forest and ExtraTrees___\n",
    "\n",
    "* _Random forest uses bootstrap replicas, that is to say, it subsamples the input data with replacement, whereas Extra Trees use the whole original sample._\n",
    "\n",
    "\n",
    "* _Another difference is the selection of cut points in order to split nodes. Random Forest chooses the optimum split while Extra Trees chooses it randomly. However, once the split points are selected, the two algorithms choose the best one between all the subset of features. Therefore, Extra Trees adds randomization but still has optimization._\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages / libraries\n",
    "\n",
    "import os #provides functions for interacting with the operating system\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "import math\n",
    "from math import sqrt\n",
    "import random\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___ExtraTrees Classifier___\n",
    "\n",
    "_[BNP Paribas Cardif Claims Management - Download Data](https://www.kaggle.com/c/bnp-paribas-cardif-claims-management/data)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>v10</th>\n",
       "      <th>...</th>\n",
       "      <th>v122</th>\n",
       "      <th>v123</th>\n",
       "      <th>v124</th>\n",
       "      <th>v125</th>\n",
       "      <th>v126</th>\n",
       "      <th>v127</th>\n",
       "      <th>v128</th>\n",
       "      <th>v129</th>\n",
       "      <th>v130</th>\n",
       "      <th>v131</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.335739</td>\n",
       "      <td>8.727474</td>\n",
       "      <td>C</td>\n",
       "      <td>3.921026</td>\n",
       "      <td>7.915266</td>\n",
       "      <td>2.599278</td>\n",
       "      <td>3.176895</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>9.999999</td>\n",
       "      <td>0.503281</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.989780</td>\n",
       "      <td>0.035754</td>\n",
       "      <td>AU</td>\n",
       "      <td>1.804126</td>\n",
       "      <td>3.113719</td>\n",
       "      <td>2.024285</td>\n",
       "      <td>0</td>\n",
       "      <td>0.636365</td>\n",
       "      <td>2.857144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.191265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.301630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.312910</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.598896</td>\n",
       "      <td>AF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.957825</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.943877</td>\n",
       "      <td>5.310079</td>\n",
       "      <td>C</td>\n",
       "      <td>4.410969</td>\n",
       "      <td>5.326159</td>\n",
       "      <td>3.979592</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>0.019645</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>...</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>2.477596</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>AE</td>\n",
       "      <td>1.773709</td>\n",
       "      <td>3.922193</td>\n",
       "      <td>1.120468</td>\n",
       "      <td>2</td>\n",
       "      <td>0.883118</td>\n",
       "      <td>1.176472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.797415</td>\n",
       "      <td>8.304757</td>\n",
       "      <td>C</td>\n",
       "      <td>4.225930</td>\n",
       "      <td>11.627438</td>\n",
       "      <td>2.097700</td>\n",
       "      <td>1.987549</td>\n",
       "      <td>0.171947</td>\n",
       "      <td>8.965516</td>\n",
       "      <td>6.542669</td>\n",
       "      <td>...</td>\n",
       "      <td>7.018256</td>\n",
       "      <td>1.812795</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>CJ</td>\n",
       "      <td>1.415230</td>\n",
       "      <td>2.954381</td>\n",
       "      <td>1.990847</td>\n",
       "      <td>1</td>\n",
       "      <td>1.677108</td>\n",
       "      <td>1.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.050328</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         v1        v2 v3        v4         v5        v6        v7        v8  \\\n",
       "0  1.335739  8.727474  C  3.921026   7.915266  2.599278  3.176895  0.012941   \n",
       "1       NaN       NaN  C       NaN   9.191265       NaN       NaN  2.301630   \n",
       "2  0.943877  5.310079  C  4.410969   5.326159  3.979592  3.928571  0.019645   \n",
       "3  0.797415  8.304757  C  4.225930  11.627438  2.097700  1.987549  0.171947   \n",
       "4       NaN       NaN  C       NaN        NaN       NaN       NaN       NaN   \n",
       "\n",
       "          v9       v10  ...      v122      v123      v124  v125      v126  \\\n",
       "0   9.999999  0.503281  ...  8.000000  1.989780  0.035754    AU  1.804126   \n",
       "1        NaN  1.312910  ...       NaN       NaN  0.598896    AF       NaN   \n",
       "2  12.666667  0.765864  ...  9.333333  2.477596  0.013452    AE  1.773709   \n",
       "3   8.965516  6.542669  ...  7.018256  1.812795  0.002267    CJ  1.415230   \n",
       "4        NaN  1.050328  ...       NaN       NaN       NaN     Z       NaN   \n",
       "\n",
       "       v127      v128  v129      v130      v131  \n",
       "0  3.113719  2.024285     0  0.636365  2.857144  \n",
       "1       NaN  1.957825     0       NaN       NaN  \n",
       "2  3.922193  1.120468     2  0.883118  1.176472  \n",
       "3  2.954381  1.990847     1  1.677108  1.034483  \n",
       "4       NaN       NaN     0       NaN       NaN  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## LOADING THE DATA\n",
    "## training data\n",
    "train = pd.read_csv(r'C:\\Users\\PiyushSin\\Downloads\\BNP\\train.csv')\n",
    "target = train['target'].values\n",
    "train = train.drop(['ID','target'],axis=1)\n",
    "\n",
    "## test data (awaiting predictions)\n",
    "test = pd.read_csv(r'C:\\Users\\PiyushSin\\Downloads\\BNP\\test.csv')\n",
    "test_ID = test['ID'].values\n",
    "test = test.drop(['ID'],axis=1)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA PREPARATION\n",
    "for (train_name, train_series), (test_name, test_series) in zip(train.iteritems(), test.iteritems()):\n",
    "    if train_series.dtype == 'object':\n",
    "        ## for objects: factorize\n",
    "        train[train_name], tmp_indexer = pd.factorize(train[train_name])\n",
    "        test[test_name] = tmp_indexer.get_indexer(test[test_name])\n",
    "        ## but now we have -1 values (NaN)\n",
    "    elif train_series.dtype=='int':\n",
    "        ## for int: fill in NaN\n",
    "        ## train data set\n",
    "        tmp_len = len(train[train_series.isnull()])\n",
    "        if tmp_len>0:\n",
    "            train.loc[train_series.isnull(), train_name] = -9999 #fillna\n",
    "        ## and test\n",
    "        tmp_len = len(test[test_series.isnull()])\n",
    "        if tmp_len>0:\n",
    "            test.loc[test_series.isnull(), test_name] = -9999  #fillna\n",
    "    else:\n",
    "        tmp_len = len(train[train_series.isnull()])\n",
    "        ## for float: fill in series.mean\n",
    "        ## train data set\n",
    "        if tmp_len>0:\n",
    "            #print \"mean\", train_series.mean()\n",
    "            train.loc[train_series.isnull(), train_name] = train_series.mean()\n",
    "        #and test data set\n",
    "        tmp_len = len(test[test_series.isnull()])\n",
    "        if tmp_len>0:\n",
    "            #print \"mean\", test_series.mean()\n",
    "            test.loc[test_series.isnull(), test_name] = test_series.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>v10</th>\n",
       "      <th>...</th>\n",
       "      <th>v122</th>\n",
       "      <th>v123</th>\n",
       "      <th>v124</th>\n",
       "      <th>v125</th>\n",
       "      <th>v126</th>\n",
       "      <th>v127</th>\n",
       "      <th>v128</th>\n",
       "      <th>v129</th>\n",
       "      <th>v130</th>\n",
       "      <th>v131</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.335739</td>\n",
       "      <td>8.727474</td>\n",
       "      <td>0</td>\n",
       "      <td>3.921026</td>\n",
       "      <td>7.915266</td>\n",
       "      <td>2.599278</td>\n",
       "      <td>3.176895</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>9.999999</td>\n",
       "      <td>0.503281</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.989780</td>\n",
       "      <td>0.035754</td>\n",
       "      <td>0</td>\n",
       "      <td>1.804126</td>\n",
       "      <td>3.113719</td>\n",
       "      <td>2.024285</td>\n",
       "      <td>0</td>\n",
       "      <td>0.636365</td>\n",
       "      <td>2.857144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.630686</td>\n",
       "      <td>7.464411</td>\n",
       "      <td>0</td>\n",
       "      <td>4.145098</td>\n",
       "      <td>9.191265</td>\n",
       "      <td>2.436402</td>\n",
       "      <td>2.483921</td>\n",
       "      <td>2.301630</td>\n",
       "      <td>9.031859</td>\n",
       "      <td>1.312910</td>\n",
       "      <td>...</td>\n",
       "      <td>6.822439</td>\n",
       "      <td>3.549938</td>\n",
       "      <td>0.598896</td>\n",
       "      <td>1</td>\n",
       "      <td>1.672658</td>\n",
       "      <td>3.239542</td>\n",
       "      <td>1.957825</td>\n",
       "      <td>0</td>\n",
       "      <td>1.925763</td>\n",
       "      <td>1.739389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.943877</td>\n",
       "      <td>5.310079</td>\n",
       "      <td>0</td>\n",
       "      <td>4.410969</td>\n",
       "      <td>5.326159</td>\n",
       "      <td>3.979592</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>0.019645</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>...</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>2.477596</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>2</td>\n",
       "      <td>1.773709</td>\n",
       "      <td>3.922193</td>\n",
       "      <td>1.120468</td>\n",
       "      <td>2</td>\n",
       "      <td>0.883118</td>\n",
       "      <td>1.176472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.797415</td>\n",
       "      <td>8.304757</td>\n",
       "      <td>0</td>\n",
       "      <td>4.225930</td>\n",
       "      <td>11.627438</td>\n",
       "      <td>2.097700</td>\n",
       "      <td>1.987549</td>\n",
       "      <td>0.171947</td>\n",
       "      <td>8.965516</td>\n",
       "      <td>6.542669</td>\n",
       "      <td>...</td>\n",
       "      <td>7.018256</td>\n",
       "      <td>1.812795</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>3</td>\n",
       "      <td>1.415230</td>\n",
       "      <td>2.954381</td>\n",
       "      <td>1.990847</td>\n",
       "      <td>1</td>\n",
       "      <td>1.677108</td>\n",
       "      <td>1.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.630686</td>\n",
       "      <td>7.464411</td>\n",
       "      <td>0</td>\n",
       "      <td>4.145098</td>\n",
       "      <td>8.742359</td>\n",
       "      <td>2.436402</td>\n",
       "      <td>2.483921</td>\n",
       "      <td>1.496569</td>\n",
       "      <td>9.031859</td>\n",
       "      <td>1.050328</td>\n",
       "      <td>...</td>\n",
       "      <td>6.822439</td>\n",
       "      <td>3.549938</td>\n",
       "      <td>0.919812</td>\n",
       "      <td>4</td>\n",
       "      <td>1.672658</td>\n",
       "      <td>3.239542</td>\n",
       "      <td>2.030373</td>\n",
       "      <td>0</td>\n",
       "      <td>1.925763</td>\n",
       "      <td>1.739389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         v1        v2  v3        v4         v5        v6        v7        v8  \\\n",
       "0  1.335739  8.727474   0  3.921026   7.915266  2.599278  3.176895  0.012941   \n",
       "1  1.630686  7.464411   0  4.145098   9.191265  2.436402  2.483921  2.301630   \n",
       "2  0.943877  5.310079   0  4.410969   5.326159  3.979592  3.928571  0.019645   \n",
       "3  0.797415  8.304757   0  4.225930  11.627438  2.097700  1.987549  0.171947   \n",
       "4  1.630686  7.464411   0  4.145098   8.742359  2.436402  2.483921  1.496569   \n",
       "\n",
       "          v9       v10  ...      v122      v123      v124  v125      v126  \\\n",
       "0   9.999999  0.503281  ...  8.000000  1.989780  0.035754     0  1.804126   \n",
       "1   9.031859  1.312910  ...  6.822439  3.549938  0.598896     1  1.672658   \n",
       "2  12.666667  0.765864  ...  9.333333  2.477596  0.013452     2  1.773709   \n",
       "3   8.965516  6.542669  ...  7.018256  1.812795  0.002267     3  1.415230   \n",
       "4   9.031859  1.050328  ...  6.822439  3.549938  0.919812     4  1.672658   \n",
       "\n",
       "       v127      v128  v129      v130      v131  \n",
       "0  3.113719  2.024285     0  0.636365  2.857144  \n",
       "1  3.239542  1.957825     0  1.925763  1.739389  \n",
       "2  3.922193  1.120468     2  0.883118  1.176472  \n",
       "3  2.954381  1.990847     1  1.677108  1.034483  \n",
       "4  3.239542  2.030373     0  1.925763  1.739389  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train\n",
    "X_test = test\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valdt, y_train, y_valdt = train_test_split(X_train,target,test_size = 0.2, random_state = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(criterion='entropy', max_depth=30, max_features=30,\n",
       "                     min_samples_leaf=2, min_samples_split=20, n_estimators=200,\n",
       "                     n_jobs=-1, random_state=24)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "extrTrClassfr = ExtraTreesClassifier(n_estimators=200,\n",
    "                                     max_features= 30,\n",
    "                                     criterion= 'entropy',\n",
    "                                     min_samples_split= 20,\n",
    "                                     max_depth= 30,\n",
    "                                     min_samples_leaf= 2, ## the default is 1 (note we use more than one sample for the split)\n",
    "                                     n_jobs= -1,\n",
    "                                     random_state=24)\n",
    "\n",
    "extrTrClassfr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'log_loss'[validation set]: 0.46439\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "valdt_PredProb = extrTrClassfr.predict_proba(X_valdt)\n",
    "\n",
    "log_loss = log_loss(y_valdt, valdt_PredProb)\n",
    "print('\\'log_loss\\'[validation set]: %.5f' %log_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___ExtraTrees Regressor___\n",
    "\n",
    "_[Mercedes-Benz Greener Manufacturing - Download Data](https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/data)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'C:\\Users\\PiyushSin\\Downloads\\Mercedes\\train.csv')\n",
    "test = pd.read_csv(r'C:\\Users\\PiyushSin\\Downloads\\Mercedes\\test.csv')\n",
    "\n",
    "y_train = train['y'].values\n",
    "id_test = test['ID']\n",
    "\n",
    "num_train = len(train)\n",
    "df_all = pd.concat([train, test])\n",
    "df_all.drop(['ID', 'y'], axis=1, inplace=True)\n",
    "\n",
    "# One-hot encoding of categorical/strings\n",
    "df_all = pd.get_dummies(df_all, drop_first=True)\n",
    "\n",
    "train = df_all[:num_train]\n",
    "test = df_all[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "model = ExtraTreesRegressor(n_estimators=100, n_jobs=4, min_samples_split=25,\n",
    "                            min_samples_leaf=35, max_features=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.558797 using {'max_features': 150}\n"
     ]
    }
   ],
   "source": [
    "# Parameter Tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gsc = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid={\n",
    "        #'n_estimators': range(50,126,25),\n",
    "        'max_features': range(50,401,50),\n",
    "        #'min_samples_leaf': range(20,50,5),\n",
    "        #'min_samples_split': range(15,36,5),\n",
    "    },\n",
    "    scoring='r2',\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "grid_result = gsc.fit(train, y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor(max_features=150)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting tuned model\n",
    "\n",
    "model = ExtraTreesRegressor(**grid_result.best_params_)\n",
    "model.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>76.086450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>96.343250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>76.356100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>76.621100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>111.285650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4204</th>\n",
       "      <td>8410</td>\n",
       "      <td>103.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>8411</td>\n",
       "      <td>96.637850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4206</th>\n",
       "      <td>8413</td>\n",
       "      <td>94.211267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>8414</td>\n",
       "      <td>110.562200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4208</th>\n",
       "      <td>8416</td>\n",
       "      <td>90.804400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4209 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID           y\n",
       "0        1   76.086450\n",
       "1        2   96.343250\n",
       "2        3   76.356100\n",
       "3        4   76.621100\n",
       "4        5  111.285650\n",
       "...    ...         ...\n",
       "4204  8410  103.820000\n",
       "4205  8411   96.637850\n",
       "4206  8413   94.211267\n",
       "4207  8414  110.562200\n",
       "4208  8416   90.804400\n",
       "\n",
       "[4209 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction \n",
    "pd.DataFrame({'ID': id_test, 'y': model.predict(test)})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
